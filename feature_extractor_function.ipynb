{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwR1Q6HLNm5+MoXuyU3fEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadityane93/SortingLine-ml/blob/main/feature_extractor_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVJSiaQ8m4g_",
        "outputId": "c8b23cb7-a60b-4e7c-95b5-55b51ab1d4ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tsfresh\n",
            "  Downloading tsfresh-0.21.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from tsfresh) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from tsfresh) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from tsfresh) (2.2.2)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.11/dist-packages (from tsfresh) (0.14.4)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from tsfresh) (1.0.1)\n",
            "Collecting pywavelets (from tsfresh)\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from tsfresh) (1.6.1)\n",
            "Requirement already satisfied: tqdm>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from tsfresh) (4.67.1)\n",
            "Collecting stumpy>=1.7.2 (from tsfresh)\n",
            "  Downloading stumpy-1.13.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tsfresh) (3.1.1)\n",
            "Requirement already satisfied: scipy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from tsfresh) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25.0->tsfresh) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25.0->tsfresh) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25.0->tsfresh) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.9.1->tsfresh) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.9.1->tsfresh) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.9.1->tsfresh) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.9.1->tsfresh) (2025.1.31)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->tsfresh) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->tsfresh) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13->tsfresh) (24.2)\n",
            "Requirement already satisfied: numba>=0.57.1 in /usr/local/lib/python3.11/dist-packages (from stumpy>=1.7.2->tsfresh) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57.1->stumpy>=1.7.2->tsfresh) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25.0->tsfresh) (1.17.0)\n",
            "Downloading tsfresh-0.21.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stumpy-1.13.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.5/176.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pywavelets, stumpy, tsfresh\n",
            "Successfully installed pywavelets-1.8.0 stumpy-1.13.0 tsfresh-0.21.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tsfresh\n",
        "# getml --upgrade\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tsfresh import extract_features, select_features\n",
        "from tsfresh.utilities.dataframe_functions import impute\n",
        "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_predict, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "folder_id = '1ps_Bh93KQRJ4WbnilORmKd1BaWUXtmt1' # files\n",
        "\n",
        "folder_list = drive.ListFile({'q': \"'{}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false\".format(folder_id)}).GetList()\n",
        "\n",
        "\n",
        "for folder in folder_list:\n",
        "    folder_title = folder['title']\n",
        "    print(f\"Processing folder: {folder_title}\")\n",
        "    file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(folder['id'])}).GetList()\n",
        "\n",
        "    for index, file in enumerate(file_list):\n",
        "        file_title = file['title']\n",
        "        print(f\"Downloading {file_title}\")\n",
        "        file.GetContentFile(file_title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAnBwrbYnDne",
        "outputId": "a338c22a-d5d1-4682-d7ac-f28781ed5e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing folder: 400hz\n",
            "Downloading 400hz-test-feature-50percent-100files.csv\n",
            "Downloading 400hz-train-feature-50percent-100files.csv\n",
            "Downloading 400hz-test-target-50percent-100files.csv\n",
            "Downloading 400hz-train-target-50percent-100files.csv\n",
            "Downloading 400hz-test-feature-50percent-10files.csv\n",
            "Downloading 400hz-train-feature-50percent-10files.csv\n",
            "Downloading 400hz-train-target-50percent-10files.csv\n",
            "Downloading 400hz-test-target-50percent-10files.csv\n",
            "Downloading 400hz-test-feature-20percent-1000files.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hzs=[400]\n",
        "percents=[20, 50]\n",
        "files_count=[1000]"
      ],
      "metadata": {
        "id": "Lhod2-sgnciF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def file_downloader(file_name,file_var):\n",
        "    file_var.to_csv(file_name, sep=',')\n",
        "    print (f'Downloading {file_name}')\n",
        "    files.download(file_name)"
      ],
      "metadata": {
        "id": "gYhYezrfBYDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filename):\n",
        "  return pd.read_csv(filename, sep=',')\n",
        "def file_reader(hz,percent,files_count):\n",
        "  train_feature = pd.DataFrame(read_file(f'{hz}hz-train-feature-{percent}percent-{files_count}files.csv'))\n",
        "  test_feature = pd.DataFrame(read_file(f'{hz}hz-test-feature-{percent}percent-{files_count}files.csv'))\n",
        "  train_target = pd.DataFrame(read_file(f'{hz}hz-train-target-{percent}percent-{files_count}files.csv'))\n",
        "  test_target = pd.DataFrame(read_file(f'{hz}hz-test-target-{percent}percent-{files_count}files.csv'))\n",
        "\n",
        "  train_feature = train_feature.drop(columns=['Unnamed: 0', 'Datum', 'P_In(W)','P_Out(W)','Energie_In(Wh)','Energie_Out(Wh)','color'])\n",
        "  test_feature = test_feature.drop(columns=['Unnamed: 0', 'Datum', 'P_In(W)','P_Out(W)','Energie_In(Wh)','Energie_Out(Wh)','color'])\n",
        "  train_target = train_target.drop(columns=['Unnamed: 0'])['color']\n",
        "  test_target = test_target.drop(columns=['Unnamed: 0'])['color']\n",
        "\n",
        "  return train_feature, test_feature, train_target, test_target"
      ],
      "metadata": {
        "id": "tLv2ImBbm_YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for hz in hzs:\n",
        "  for file in files_count:\n",
        "    if file == 10 or file == 100:\n",
        "      percent = 50\n",
        "    else:\n",
        "      percent = 20\n",
        "    print (f'working with -----  hz: {hz}, percent: {percent}, files: {file}')\n",
        "\n",
        "    train_feature, test_feature, train_target, test_target = file_reader(hz,percent,file)\n",
        "\n",
        "    print(\"Extracting features from train part\")\n",
        "    extracted_features_train =  extract_features(\n",
        "        train_feature,\n",
        "        column_id=\"fileno\",\n",
        "        column_sort=\"Uhrzeit\",\n",
        "        impute_function=impute,\n",
        "        n_jobs=4\n",
        "    )\n",
        "\n",
        "    print(\"Extracting features from test part\")\n",
        "    extracted_features_test = extract_features(\n",
        "        test_feature,\n",
        "        column_id=\"fileno\",\n",
        "        column_sort=\"Uhrzeit\",\n",
        "        impute_function=impute,\n",
        "    )\n",
        "\n",
        "    feature_file_train = f'extracted-{hz}hz-train-feature-{percent}percent-{file}files.csv'\n",
        "    target_file_train = f'extracted-{hz}hz-train-target-{percent}percent-{file}files.csv'\n",
        "    feature_file_test = f'extracted-{hz}hz-test-feature-{percent}percent-{file}files.csv'\n",
        "    target_file_test = f'extracted-{hz}hz-test-target-{percent}percent-{file}files.csv'\n",
        "\n",
        "    file_downloader(feature_file_train,extracted_features_train)\n",
        "    file_downloader(target_file_train,train_target)\n",
        "    file_downloader(feature_file_test,extracted_features_test)\n",
        "    file_downloader(target_file_test,test_target)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1lSNKTGneCy",
        "outputId": "589b93c1-10ff-488c-8e7c-235df7c7791d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "working with -----  hz: 400, percent: 20, files: 1000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tsfresh.feature_extraction.settings:Dependency not available for matrix_profile, this feature will be disabled!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting features from train part\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Feature Extraction:  95%|█████████▌| 19/20 [11:42:12<32:06, 1926.16s/it]  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "print(multiprocessing.cpu_count())"
      ],
      "metadata": {
        "id": "BdZF8vmZJpBi",
        "outputId": "2baf2c77-a800-430c-8797-92917afc98b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9jdQ0Va2p3eu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}